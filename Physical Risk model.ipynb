{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c6f4c1a-f4ad-4bac-bea9-3492abc93bd5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Physical risk economic impact model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "efd592c1-f513-41e0-80e7-e4a8a66de6c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This notebook computes the effect of the propagation of physical shocks along value chains using an input-output model with the possibility of substitution of input sources among different geographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71119362-1434-4b18-bf89-0d222127cade",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f23963d-ce62-4ae2-a341-c4e67e2e169e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "First, upload the data and manage the main entities (sectors, geographies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c73e3acb-56e2-4c78-a240-c813dd3a2c4f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set the input file path\n",
    "input_file = \"MPSAM_2905.xlsx\"\n",
    "\n",
    "# Read sectors and geographies data\n",
    "sectors = pd.read_excel(input_file, sheet_name=0, usecols=\"B\", skiprows=2, header=None, nrows=1177)\n",
    "sectors.columns = [\"Sector\"]  # Explicitly set column name\n",
    "\n",
    "geographies = pd.read_excel(input_file, sheet_name=0, usecols=\"A\", skiprows=2, header=None, nrows=1177)\n",
    "geographies.columns = [\"Geography\"]  # Explicitly set column name\n",
    "\n",
    "# Number of unique sectors and geographies\n",
    "sec = sectors[\"Sector\"].nunique()\n",
    "m = geographies[\"Geography\"].nunique()\n",
    "\n",
    "# Total number of entries\n",
    "n = sec * m\n",
    "\n",
    "# Read matrices Z, VA, and FD from the Excel file\n",
    "Z = pd.read_excel(input_file, sheet_name=0, usecols=\"C:ASI\", skiprows=2,  nrows=1177, header=None).values\n",
    "VA = pd.read_excel(input_file, sheet_name=0, usecols=\"C:ASI\", skiprows=1179, nrows=4, header=None).values\n",
    "FD = pd.read_excel(input_file, sheet_name=0, usecols=\"ASM:ASP\", skiprows=2,  nrows=1177, header=None).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e5c0eeb-52d9-412a-920a-54cba21fb697",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "For the moment shocks are read from excel file. **These should become parameteres decided by the user**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e19702e5-40e8-4e61-b5f9-59018d2f6fdd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read demand (d) and supply (p) shock data\n",
    "d = pd.read_excel(input_file, sheet_name=0, usecols=\"ASR\", skiprows=2, nrows=1177, header=None).values\n",
    "p = pd.read_excel(input_file, sheet_name=0, usecols=\"ASS\", skiprows=2, nrows=1177, header=None).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c244214d-94bb-4768-9fc6-b36e6fcf8657",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Compute the macro-dimensions and the direct effects on production capacity and final demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9253e92a-2956-4fac-a101-cf89eda084fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compute value added and final demand\n",
    "VA = VA.sum(axis=0)\n",
    "FD = FD.sum(axis=1)\n",
    "\n",
    "# Compute total output X\n",
    "X = Z.sum(axis=0) + VA\n",
    "\n",
    "# Compute the technical coefficient matrix A\n",
    "A = (Z/ X)\n",
    "\n",
    "# Compute the Leontief inverse L\n",
    "L = np.linalg.inv(np.eye(n) - A)\n",
    "\n",
    "# Aggregate technical coefficients by sectors\n",
    "AG = np.zeros((sec, n))\n",
    "\n",
    "# Use the correct column name \"Sector\" instead of an index\n",
    "unique_sectors = sectors[\"Sector\"].unique()\n",
    "for i in range(sec):\n",
    "    AG[i, :] = A[sectors[\"Sector\"] == unique_sectors[i], :].sum(axis=0)\n",
    "\n",
    "# Calculate maximum final demand and maximum output after shocks\n",
    "fd_max = FD * (1 - d.flatten())\n",
    "X_max = X * (1 - p.flatten())\n",
    "\n",
    "# Compute initial disrupted output\n",
    "X_md = L @ fd_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a42cf7e4-c2e9-4400-a6c6-e5dd95b85db2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Reallocation iterative algorithm: given the supply and demand shocks, the economy adjusts iteratively until the best suboptimal resources allocation is reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17c265dd-461c-4190-a396-72382e4e4221",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set parameters for the simulation\n",
    "lambda_param = 1  # reallocation capacity parameter: 0 = no reallocation capacity , 1 = full reallocation capacity\n",
    "tol = 0.01        # convergence tolerance\n",
    "\n",
    "# Initialize variables for the iteration process\n",
    "check = False\n",
    "count = 0\n",
    "\n",
    "# Iterative adjustment process\n",
    "while not check:\n",
    "    # Compute the ratio r for constraints\n",
    "    r = np.minimum(X_max / X_md, 1)\n",
    "\n",
    "    # Flatten the p array\n",
    "    p_flat = p.flatten()\n",
    "\n",
    "    # Calculate constraints for each sector\n",
    "    const = np.array([min(np.concatenate([r[Z[:, i] > 0], [1 - p_flat[i]]])) for i in range(n)])\n",
    "\n",
    "    # Apply constraints to the intermediate demand matrix Z\n",
    "    Z_const = const * Z\n",
    "        \n",
    "    # Calculate the needed intermediate demand\n",
    "    Z_need = A @ np.diag(X_md)\n",
    "        \n",
    "    # Compute excess demand\n",
    "    exD = Z_need - Z_const\n",
    "\n",
    "    # Aggregate excess demand by sectors\n",
    "    exDsecj = np.zeros((sec, n))\n",
    "    for i in range(sec):\n",
    "        exDsecj[i, :] = exD[sectors[\"Sector\"] == unique_sectors[i], :].sum(axis=0)\n",
    "    exDsec = exDsecj.sum(axis=1)\n",
    "\n",
    "    # Compute the available inventory\n",
    "    inv = np.maximum(X_max - fd_max - Z_const.sum(axis=1), 0)\n",
    "    invsec = np.array([inv[sectors[\"Sector\"] == unique_sectors[i]].sum() for i in range(sec)])\n",
    "        \n",
    "    # Compute the substitution rate\n",
    "    sub = invsec / exDsec\n",
    "\n",
    "    # Initialize reallocation matrix\n",
    "    reallocation = np.zeros((n, n))\n",
    "        \n",
    "    # Perform reallocation based on constraints and excess demand\n",
    "    for i in range(n):\n",
    "        sector_idx = np.where(unique_sectors == sectors.iloc[i, 0])[0][0]\n",
    "        reallocation[i, :] = lambda_param * inv[i] / invsec[sector_idx] * sub[sector_idx] * exDsecj[sector_idx, :]\n",
    "\n",
    "    # Update the intermediate demand matrix Z\n",
    "    Z_new = Z_const + reallocation\n",
    "\n",
    "    # Aggregate the new intermediate demand by sectors\n",
    "    ZGnew = np.zeros((sec, n))\n",
    "    for i in range(sec):\n",
    "        ZGnew[i, :] = Z_new[sectors[\"Sector\"] == unique_sectors[i], :].sum(axis=0)\n",
    "\n",
    "    # Calculate the new output matrix X_new_m and X_new\n",
    "    X_new_m = ZGnew / AG\n",
    "    X_new = np.min(X_new_m, axis=0)\n",
    "\n",
    "    # Update final demand based on the new output\n",
    "    fd_new = np.maximum(X_new - Z_new.sum(axis=1), 0)\n",
    "\n",
    "    # Update the technical coefficient matrix A_new and Leontief inverse L_new\n",
    "    A_new = (Z_new / X_new)\n",
    "    L_new = np.linalg.inv(np.eye(n) - A_new)\n",
    "\n",
    "    # Compute the target output with the new final demand\n",
    "    X_new_target = L_new @ fd_new\n",
    "\n",
    "    # Check convergence criteria\n",
    "    check = np.all(np.abs(X_new - X_new_target) < tol)\n",
    "    # Update variables for the next iteration\n",
    "    X_max = X_new\n",
    "    X_md = X_new_target\n",
    "    Z = Z_new\n",
    "    A = A_new\n",
    "    fd_max = fd_new\n",
    "    \n",
    "    # Increment the iteration count\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5353d847-9229-4fef-8d89-05f883b6c5e9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Once the algorithm has converged, compute final outcomes and main impact ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69c3f659-2bcc-4f6a-bf05-9e8d1fe8f3ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Added Impact Ratio: 1.000000000000067\n",
      "Production Impact Ratio: 0.7851758251371754\n"
     ]
    }
   ],
   "source": [
    "# Compute the new value added\n",
    "VA_new = X_new - Z_new.sum(axis=0)\n",
    "\n",
    "# Calculate aggregate results\n",
    "FD_shock = fd_max.sum() - FD.sum()\n",
    "Prod_shock = -p.flatten() @ X\n",
    "VA_impact = VA_new.sum() - VA.sum()\n",
    "Prod_impact = X_new.sum() - X.sum()\n",
    "\n",
    "# Output the key ratios\n",
    "VA_impact_ratio = VA_impact / FD_shock\n",
    "Prod_impact_ratio = Prod_impact / Prod_shock\n",
    "\n",
    "print(f\"Value Added Impact Ratio: {VA_impact_ratio}\")\n",
    "print(f\"Production Impact Ratio: {Prod_impact_ratio}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Physical Risk model",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
